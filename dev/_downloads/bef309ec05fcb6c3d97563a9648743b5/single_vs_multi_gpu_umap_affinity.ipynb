{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSimple example of using UMAPAffinity with multi-GPU on 10x mouse Zheng dataset.\nCompares distributed vs non-distributed performance and verifies outputs are similar.\nMust be launched with torchrun for distributed execution.\n\nUsage:\n    torchrun --nproc_per_node=4 test_mnist_entropic_multigpu.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport torch\nimport torch.distributed as dist\nimport time\nimport gzip\nimport pickle\nfrom io import BytesIO\nimport requests\n\nfrom torchdr.affinity import UMAPAffinity\n\n\ndef download_and_load_dataset(url):\n    \"\"\"Download and load pickled dataset from URL.\"\"\"\n    response = requests.get(url)\n    with gzip.GzipFile(fileobj=BytesIO(response.content)) as f:\n        data = pickle.load(f)\n    return data\n\n\ndef setup_distributed():\n    \"\"\"Initialize distributed training environment.\"\"\"\n    # torchrun sets the environment variables, but we still need to init the process group\n    local_rank = int(os.environ[\"LOCAL_RANK\"])\n    torch.cuda.set_device(local_rank)\n    dist.init_process_group(\n        backend=\"nccl\", device_id=torch.device(f\"cuda:{local_rank}\")\n    )\n\n\ndef cleanup_distributed():\n    \"\"\"Clean up distributed training environment.\"\"\"\n    if dist.is_initialized():\n        dist.destroy_process_group()\n\n\ndef main():\n    # Initialize distributed training\n    setup_distributed()\n    rank = dist.get_rank()\n    world_size = dist.get_world_size()\n\n    # Print from all ranks to verify all GPUs are active\n    print(\n        f\"[Rank {rank}] Process started on GPU {torch.cuda.current_device()}, device name: {torch.cuda.get_device_name()}\"\n    )\n    dist.barrier()  # Synchronize before continuing\n\n    if rank == 0:\n        print(f\"\\nRunning comparison on {world_size} GPUs\")\n        print(\"Loading 10x mouse Zheng dataset...\")\n\n    # Download and load 10x mouse Zheng data\n    url_10x = \"http://file.biolab.si/opentsne/benchmark/10x_mouse_zheng.pkl.gz\"\n    data_10x = download_and_load_dataset(url_10x)\n\n    # Data is already PCA-reduced to 50 dimensions\n    x = data_10x[\"pca_50\"].astype(\"float32\")\n\n    if rank == 0:\n        print(f\"Data already PCA-reduced to 50 dimensions\")\n\n    # Convert to tensor (data stays on CPU)\n    X = torch.tensor(x, dtype=torch.float32)\n\n    if rank == 0:\n        print(f\"Data shape: {X.shape}\")\n        print(\"\\n\" + \"=\" * 60)\n        print(\"TEST 1: Multi-GPU UMAPAffinity (distributed=True)\")\n        print(\"=\" * 60)\n        start_time = time.time()\n\n    # Create UMAPAffinity with distributed=True\n    affinity_distributed = UMAPAffinity(\n        n_neighbors=30,\n        metric=\"sqeuclidean\",\n        verbose=(rank == 0),\n        device=\"cuda\",\n        backend=\"faiss\",\n        sparsity=True,\n        distributed=True,  # Force distributed mode\n    )\n\n    # Compute affinity matrix with distributed mode\n    P_dist, indices_distributed = affinity_distributed(X, log=False)\n\n    # Synchronize all GPUs\n    if dist.is_initialized():\n        dist.barrier()\n\n    if rank == 0:\n        distributed_time = time.time() - start_time\n        print(f\"\\nMulti-GPU computation completed in {distributed_time:.2f} seconds\")\n\n        print(\"\\n\" + \"=\" * 60)\n        print(\"TEST 2: Single-GPU UMAPAffinity (distributed=False)\")\n        print(\"=\" * 60)\n        start_time = time.time()\n\n    # Only rank 0 computes the single-GPU version\n    if rank == 0:\n        # Create UMAPAffinity with distributed=False\n        affinity_single = UMAPAffinity(\n            n_neighbors=30,\n            metric=\"sqeuclidean\",\n            verbose=True,\n            device=\"cuda\",\n            backend=\"faiss\",\n            sparsity=True,\n            symmetrize=False,  # Match multi-GPU behavior\n            distributed=False,  # Force single-GPU mode\n        )\n\n        # Compute affinity matrix with single GPU\n        P_single, indices_single = affinity_single(X, log=False)\n\n        single_time = time.time() - start_time\n        print(f\"\\nSingle-GPU computation completed in {single_time:.2f} seconds\")\n\n        # Compare results\n        print(\"\\n\" + \"=\" * 60)\n        print(\"COMPARISON RESULTS\")\n        print(\"=\" * 60)\n\n        # Timing comparison\n        print(f\"\\nTiming:\")\n        print(f\"  Multi-GPU ({world_size} GPUs): {distributed_time:.2f} seconds\")\n        print(f\"  Single-GPU: {single_time:.2f} seconds\")\n        print(f\"  Speedup: {single_time / distributed_time:.2f}x\")\n\n        # Output shape comparison\n        print(f\"\\nOutput shapes:\")\n        print(f\"  Multi-GPU affinity shape: {P_dist.shape}\")\n        print(f\"  Single-GPU affinity shape: {P_single.shape}\")\n        print(f\"  Multi-GPU indices shape: {indices_distributed.shape}\")\n        print(f\"  Single-GPU indices shape: {indices_single.shape}\")\n\n        print(f\"\\nAffinity statistics (Multi-GPU):\")\n        print(f\"  Min value: {P_dist.min().item():.6e}\")\n        print(f\"  Max value: {P_dist.max().item():.6e}\")\n        print(f\"  Mean value: {P_dist.mean().item():.6e}\")\n\n        print(f\"\\nAffinity statistics (Single-GPU):\")\n        print(f\"  Min value: {P_single.min().item():.6e}\")\n        print(f\"  Max value: {P_single.max().item():.6e}\")\n        print(f\"  Mean value: {P_single.mean().item():.6e}\")\n\n        # Check similarity of outputs (P_dist is chunked, P_single is full)\n        print(f\"\\nOutput similarity check (comparing rank 0's chunk):\")\n\n        # Get the size of rank 0's chunk\n        chunk_size = P_dist.shape[0]\n\n        # Compare indices for the chunk\n        indices_match = torch.allclose(\n            indices_distributed, indices_single[:chunk_size], rtol=1e-5\n        )\n        print(f\"  Indices match (chunk of {chunk_size} points): {indices_match}\")\n\n        # Compare affinity values for the chunk\n        P_single_chunk = P_single[:chunk_size]\n        values_diff = torch.abs(P_dist - P_single_chunk).mean()\n        print(\n            f\"  Mean absolute difference in affinity values: {values_diff.item():.6e}\"\n        )\n\n        # Check relative difference\n        relative_diff = (\n            torch.abs(P_dist - P_single_chunk) / (P_single_chunk + 1e-10)\n        ).mean()\n        print(f\"  Mean relative difference: {relative_diff.item():.6e}\")\n\n        values_match = torch.allclose(P_dist, P_single_chunk, rtol=1e-3, atol=1e-6)\n        print(f\"  Affinity values match (rtol=1e-3): {values_match}\")\n\n    # Clean up\n    cleanup_distributed()\n\n\nif __name__ == \"__main__\":\n    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}