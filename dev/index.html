<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Torch Dimensionality Reduction &mdash; TorchDR 0.0.0-alpha documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=8e37ee27"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick Start Guide" href="torchdr.quick_start.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="#">
            
              <img src="_static/torchdr_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Torch Dimensionality Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchdr.quick_start.html">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchdr.user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="all.html">API and Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchdr.releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchdr.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">TorchDR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Torch Dimensionality Reduction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="torch-dimensionality-reduction">
<h1>Torch Dimensionality Reduction<a class="headerlink" href="#torch-dimensionality-reduction" title="Link to this heading"></a></h1>
<a class="reference internal image-reference" href="https://github.com/torchdr/torchdr/raw/main/docs/source/figures/torchdr_logo.png"><img alt="torchdr logo" class="align-center" src="https://github.com/torchdr/torchdr/raw/main/docs/source/figures/torchdr_logo.png" style="width: 800px;" /></a>
<p><a class="reference external" href="https://pytorch.org/get-started/locally/"><img alt="Pytorch" src="https://img.shields.io/badge/PyTorch_1.8+-ee4c2c?logo=pytorch&amp;logoColor=white" /></a> <a class="reference external" href="https://www.python.org/downloads/release/python-3100/"><img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10%2B-blue" /></a> <a class="reference external" href="https://github.com/psf/black"><img alt="Black" src="https://img.shields.io/badge/code%20style-black-000000.svg" /></a> <img alt="Test Status" src="https://github.com/torchdr/torchdr/actions/workflows/testing.yml/badge.svg" /> <a class="reference external" href="https://codecov.io/gh/torchdr/torchdr"><img alt="codecov" src="https://codecov.io/gh/torchdr/torchdr/branch/main/graph/badge.svg" /></a> <a class="reference external" href="https://opensource.org/licenses/BSD-3-Clause"><img alt="License" src="https://img.shields.io/badge/License-BSD_3--Clause-blue.svg" /></a></p>
<p>Github repository: <a class="reference external" href="https://github.com/torchdr/torchdr/">https://github.com/torchdr/torchdr/</a>.</p>
<p>Documentation: <a class="reference external" href="https://torchdr.github.io/dev/">https://torchdr.github.io/dev/</a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> is an open-source <strong>dimensionality reduction (DR)</strong> library using <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code>. Its goal is to accelerate the development of new DR methods by providing a common simplified framework.</p>
<p>DR aims to construct a <strong>low-dimensional representation (or embedding)</strong> of an input dataset that best preserves its <strong>geometry encoded via a pairwise affinity matrix</strong> . To this end, DR methods <strong>optimize the embedding</strong> such that its <strong>associated pairwise affinity matches the input affinity</strong>. <code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> provides a general framework for solving problems of this form. Defining a DR algorithm solely requires choosing or implementing an <code class="docutils literal notranslate"><span class="pre">Affinity</span></code> object for both input and embedding as well as an objective function.</p>
<p>Benefits of <code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> include:</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><strong>Modularity</strong></p></td>
<td><p>All of it is written in python in a highly modular way, making it easy to create or transform components.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Speed</strong></p></td>
<td><p>Supports GPU acceleration, sparsity and batching strategies with contrastive learning techniques.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Memory efficiency</strong></p></td>
<td><p>Relies on <code class="docutils literal notranslate"><span class="pre">KeOps</span></code> <a class="footnote-reference brackets" href="#id37" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></a> symbolic tensors to avoid memory overflows.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Compatibility</strong></p></td>
<td><p>Implemented methods are fully compatible with the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <a class="footnote-reference brackets" href="#id39" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>21<span class="fn-bracket">]</span></a> API and <code class="docutils literal notranslate"><span class="pre">torch</span></code> <a class="footnote-reference brackets" href="#id38" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></a> ecosystem.</p></td>
</tr>
</tbody>
</table>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Link to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> offers a <strong>user-friendly API similar to scikit-learn</strong>. It seamlessly accepts both NumPy arrays and PyTorch tensors as input, ensuring that the output matches the type and backend of the input.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">torchdr</span> <span class="kn">import</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">TSNE</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s2">&quot;mnist_784&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="n">x_</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">perplexity</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> enables <strong>GPU acceleration without memory limitations</strong> thanks to the <code class="docutils literal notranslate"><span class="pre">KeOps</span></code> library. This can be easily enabled as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">z_gpu</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">perplexity</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">keops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
</pre></div>
</div>
<p>For additional examples, visit the <a class="reference external" href="https://github.com/TorchDR/TorchDR/tree/main/examples">examples directory</a>.</p>
</section>
<section id="implemented-methods">
<h2>Implemented Methods<a class="headerlink" href="#implemented-methods" title="Link to this heading"></a></h2>
<section id="affinities">
<h3>Affinities<a class="headerlink" href="#affinities" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> features a wide range of affinity matrices which can then be used as a building block for DR algorithms. It includes:</p>
<ul class="simple">
<li><p>Usual affinities such that scalar product, Gaussian and Student kernels.</p></li>
<li><p>Self-tuning affinities <a class="footnote-reference brackets" href="#id40" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>22<span class="fn-bracket">]</span></a>.</p></li>
<li><p>Doubly stochastic affinities with entropic <a class="footnote-reference brackets" href="#id23" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> <a class="footnote-reference brackets" href="#id24" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a> <a class="footnote-reference brackets" href="#id25" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> <a class="footnote-reference brackets" href="#id34" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></a> and quadratic <a class="footnote-reference brackets" href="#id28" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a> projections.</p></li>
<li><p>Adaptive affinities with entropy control <a class="footnote-reference brackets" href="#id19" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> <a class="footnote-reference brackets" href="#id22" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> and its symmetric version <a class="footnote-reference brackets" href="#id21" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p></li>
</ul>
</section>
<section id="dr-algorithms">
<h3>DR algorithms<a class="headerlink" href="#dr-algorithms" title="Link to this heading"></a></h3>
<p><strong>Spectral.</strong> <code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> provides spectral embeddings calculated via eigenvalue decomposition of the affinities or their Laplacian.</p>
<p><strong>Neighbor Embedding.</strong> <code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> includes various neighbor embedding methods such as <em>SNE</em> <a class="footnote-reference brackets" href="#id19" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, <em>t-SNE</em> <a class="footnote-reference brackets" href="#id20" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, <em>SNEkhorn</em> / <em>t-SNEkhorn</em> <a class="footnote-reference brackets" href="#id21" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>, <em>UMAP</em> <a class="footnote-reference brackets" href="#id26" id="id16" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a>, <em>LargeVis</em> <a class="footnote-reference brackets" href="#id31" id="id17" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a> and <em>InfoTSNE</em> <a class="footnote-reference brackets" href="#id33" id="id18" role="doc-noteref"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></a>.</p>
</section>
</section>
<section id="finding-help">
<h2>Finding Help<a class="headerlink" href="#finding-help" title="Link to this heading"></a></h2>
<p>If you have any questions or suggestions, feel free to open an issue on the
<a class="reference external" href="https://github.com/torchdr/torchdr/issues">issue tracker</a> or contact <a class="reference external" href="https://huguesva.github.io/">Hugues Van Assel</a> directly.</p>
</section>
<section id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Link to this heading"></a></h2>
<p>If you use <code class="docutils literal notranslate"><span class="pre">TorchDR</span></code> in your research, please cite the following reference:</p>
<div class="highlight-apalike notranslate"><div class="highlight"><pre><span></span>Van Assel H., Courty N., Flamary R., Garivier A., Massias M., Vayer T., Vincent-Cuaz C. TorchDR URL: https://torchdr.github.io/
</pre></div>
</div>
<p>or in Bibtex format :</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span><span class="nl">vanassel2024torchdr</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Van Assel, Hugues and Courty, Nicolas and Flamary, Rémi and Garivier, Aurélien and Massias, Mathurin and Vayer, Titouan and Vincent-Cuaz, Cédric}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{TorchDR}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://torchdr.github.io/}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2024}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading"></a></h2>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id19" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id10">1</a>,<a role="doc-backlink" href="#id13">2</a>)</span>
<p>Geoffrey Hinton, Sam Roweis (2002). <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2002/file/6150ccc6069bea6b5716254057a194ef-Paper.pdf">Stochastic Neighbor Embedding</a>. Advances in Neural Information Processing Systems 15 (NeurIPS).</p>
</aside>
<aside class="footnote brackets" id="id20" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">2</a><span class="fn-bracket">]</span></span>
<p>Laurens van der Maaten, Geoffrey Hinton (2008). <a class="reference external" href="https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf?fbcl">Visualizing Data using t-SNE</a>. The Journal of Machine Learning Research 9.11 (JMLR).</p>
</aside>
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id12">1</a>,<a role="doc-backlink" href="#id15">2</a>)</span>
<p>Hugues Van Assel, Titouan Vayer, Rémi Flamary, Nicolas Courty (2023). <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/8b54ecd9823fff6d37e61ece8f87e534-Paper-Conference.pdf">SNEkhorn: Dimension Reduction with Symmetric Entropic Affinities</a>. Advances in Neural Information Processing Systems 36 (NeurIPS).</p>
</aside>
<aside class="footnote brackets" id="id22" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">4</a><span class="fn-bracket">]</span></span>
<p>Max Vladymyrov, Miguel A. Carreira-Perpinan (2013). <a class="reference external" href="https://proceedings.mlr.press/v28/vladymyrov13.pdf">Entropic Affinities: Properties and Efficient Numerical Computation</a>. International Conference on Machine Learning (ICML).</p>
</aside>
<aside class="footnote brackets" id="id23" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>Richard Sinkhorn, Paul Knopp (1967). <a class="reference external" href="https://msp.org/pjm/1967/21-2/pjm-v21-n2-p14-p.pdf">Concerning nonnegative matrices and doubly stochastic matrices</a>. Pacific Journal of Mathematics, 21(2), 343-348.</p>
</aside>
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">6</a><span class="fn-bracket">]</span></span>
<p>Marco Cuturi (2013). <a class="reference external" href="https://proceedings.neurips.cc/paper/2013/file/af21d0c97db2e27e13572cbf59eb343d-Paper.pdf">Sinkhorn Distances: Lightspeed Computation of Optimal Transport</a>. Advances in Neural Information Processing Systems 26 (NeurIPS).</p>
</aside>
<aside class="footnote brackets" id="id25" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">7</a><span class="fn-bracket">]</span></span>
<p>Jean Feydy, Thibault Séjourné, François-Xavier Vialard, Shun-ichi Amari, Alain Trouvé, Gabriel Peyré (2019). <a class="reference external" href="https://proceedings.mlr.press/v89/feydy19a/feydy19a.pdf">Interpolating between Optimal Transport and MMD using Sinkhorn Divergences</a>. International Conference on Artificial Intelligence and Statistics (AISTATS).</p>
</aside>
<aside class="footnote brackets" id="id26" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id16">8</a><span class="fn-bracket">]</span></span>
<p>Leland McInnes, John Healy, James Melville (2018). <a class="reference external" href="https://arxiv.org/abs/1802.03426">UMAP: Uniform manifold approximation and projection for dimension reduction</a>. arXiv preprint arXiv:1802.03426.</p>
</aside>
<aside class="footnote brackets" id="id27" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></span>
<p>Yao Lu, Jukka Corander, Zhirong Yang (2019). <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0167865518305099">Doubly Stochastic Neighbor Embedding on Spheres</a>. Pattern Recognition Letters 128 : 100-106.</p>
</aside>
<aside class="footnote brackets" id="id28" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">10</a><span class="fn-bracket">]</span></span>
<p>Stephen Zhang, Gilles Mordant, Tetsuya Matsumoto, Geoffrey Schiebinger (2023). <a class="reference external" href="https://arxiv.org/abs/2307.09816">Manifold Learning with Sparse Regularised Optimal Transport</a>. arXiv preprint.</p>
</aside>
<aside class="footnote brackets" id="id29" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></span>
<p>Ham, J., Lee, D. D., Mika, S., &amp; Schölkopf, B. (2004). <a class="reference external" href="https://icml.cc/Conferences/2004/proceedings/papers/296.pdf">A kernel view of the dimensionality reduction of manifolds</a>. In Proceedings of the twenty-first international conference on Machine learning (ICML).</p>
</aside>
<aside class="footnote brackets" id="id30" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Sebastian Damrich, Fred Hamprecht (2021). <a class="reference external" href="https://proceedings.neurips.cc/paper/2021/file/2de5d16682c3c35007e4e92982f1a2ba-Paper.pdf">On UMAP’s True Loss Function</a>. Advances in Neural Information Processing Systems 34 (NeurIPS).</p>
</aside>
<aside class="footnote brackets" id="id31" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">13</a><span class="fn-bracket">]</span></span>
<p>Tang, J., Liu, J., Zhang, M., &amp; Mei, Q. (2016). <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/2872427.2883041?casa_token=9ybi1tW9opcAAAAA:yVfVBu47DYa5_cpmJnQZm4PPWaTdVJgRu2pIMqm3nvNrZV5wEsM9pde03fCWixTX0_AlT-E7D3QRZw">Visualizing Large-Scale and High-Dimensional Data</a>. In Proceedings of the 25th international conference on world wide web.</p>
</aside>
<aside class="footnote brackets" id="id32" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Artemenkov, A., &amp; Panov, M. (2020). <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3366423.3380061?casa_token=J-quI6odZDMAAAAA:dEKrwbHIaiPX1xZQe2NA2q3-PahWc4PUP6WDtQVRocIa501T_LGgPixl03lVJF3j5SjutiBzhj9cpg">NCVis: Noise Contrastive Approach for Scalable Visualization</a>. In Proceedings of The Web Conference.</p>
</aside>
<aside class="footnote brackets" id="id33" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">15</a><span class="fn-bracket">]</span></span>
<p>Sebastian Damrich, Jan Niklas Böhm, Fred Hamprecht, Dmitry Kobak (2023). <a class="reference external" href="https://openreview.net/pdf?id=B8a1FcY0vi">From t-SNE to UMAP with contrastive learning</a>. International Conference on Learning Representations (ICLR).</p>
</aside>
<aside class="footnote brackets" id="id34" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">16</a><span class="fn-bracket">]</span></span>
<p>Landa, B., Coifman, R. R., &amp; Kluger, Y. (2021). <a class="reference external" href="https://epubs.siam.org/doi/abs/10.1137/20M1342124?journalCode=sjmdaq">Doubly stochastic normalization of the gaussian kernel is robust to heteroskedastic noise</a>. SIAM journal on mathematics of data science, 3(1), 388-413.</p>
</aside>
<aside class="footnote brackets" id="id35" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></span>
<p>Hugues Van Assel, Thibault Espinasse, Julien Chiquet, &amp; Franck Picard (2022). <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/45994782a61bb51cad5c2bae36834265-Paper-Conference.pdf">A Probabilistic Graph Coupling View of Dimension Reduction</a>. Advances in Neural Information Processing Systems 35 (NeurIPS).</p>
</aside>
<aside class="footnote brackets" id="id36" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Böhm, J. N., Berens, P., &amp; Kobak, D. (2022). <a class="reference external" href="https://www.jmlr.org/papers/volume23/21-0055/21-0055.pdf">Attraction-Repulsion Spectrum in Neighbor Embeddings</a>. Journal of Machine Learning Research, 23 (JMLR).</p>
</aside>
<aside class="footnote brackets" id="id37" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">19</a><span class="fn-bracket">]</span></span>
<p>Charlier, B., Feydy, J., Glaunes, J. A., Collin, F. D., &amp; Durif, G. (2021). <a class="reference external" href="https://www.jmlr.org/papers/volume22/20-275/20-275.pdf">Kernel Operations on the GPU, with Autodiff, without Memory Overflows</a>. Journal of Machine Learning Research, 22 (JMLR).</p>
</aside>
<aside class="footnote brackets" id="id38" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">20</a><span class="fn-bracket">]</span></span>
<p>Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., … &amp; Chintala, S. (2019). <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf">Pytorch: An imperative style, high-performance deep learning library</a>. Advances in neural information processing systems 32 (NeurIPS).</p>
</aside>
<aside class="footnote brackets" id="id39" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">21</a><span class="fn-bracket">]</span></span>
<p>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., … &amp; Duchesnay, É. (2011). <a class="reference external" href="https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf?ref=https:/">Scikit-learn: Machine learning in Python</a>. Journal of machine Learning research, 12 (JMLR).</p>
</aside>
<aside class="footnote brackets" id="id40" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">22</a><span class="fn-bracket">]</span></span>
<p>Max Zelnik-Manor, L., &amp; Perona, P. (2004). <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2004/file/40173ea48d9567f1f393b20c855bb40b-Paper.pdf">Self-Tuning Spectral Clustering</a>. Advances in Neural Information Processing Systems 17 (NeurIPS).</p>
</aside>
</aside>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="torchdr.quick_start.html" class="btn btn-neutral float-right" title="Quick Start Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, TorchDR team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>