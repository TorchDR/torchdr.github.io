{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Entropic Affinities can adapt to varying noise levels\n\nWe show the adaptivity property of entropic affinities on a toy\nsimulated dataset with heteroscedastic noise.\n\nWe use the following modules from ``TorchDR``:\n\n.. autosummary::\n   :toctree: stubs\n   :template: myclass_template.rst\n   torchdr.affinity.GibbsAffinity\n   torchdr.affinity.EntropicAffinity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nfrom torchdr import (\n    GibbsAffinity,\n    EntropicAffinity,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We generate three Gaussian clusters of points with different standard deviations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(10)\nn_cluster = 20  # number of points per cluster\n\nX1 = torch.Tensor([-10, -10])[None, :] + torch.normal(\n    0, 1, size=(n_cluster, 2), dtype=torch.double\n)\nX2 = torch.Tensor([10, -10])[None, :] + torch.normal(\n    0, 3, size=(n_cluster, 2), dtype=torch.double\n)\nX3 = torch.Tensor([0, 10])[None, :] + torch.normal(\n    0, 4, size=(n_cluster, 2), dtype=torch.double\n)\n\nX = torch.cat([X1, X2, X3], 0)\n\n\ndef plot_affinity_graph(G):\n    for i in range(3 * n_cluster):\n        for j in range(i):\n            plt.plot(\n                [X[i, 0], X[j, 0]],\n                [X[i, 1], X[j, 1]],\n                color=\"black\",\n                alpha=G[i, j].item(),\n            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Row-normalised Gibbs affinity with constant bandwidth\n\nWe first consider a Gibbs affinity, normalized by row,\nwith a **constant bandwidth**.\nSuch a global bandwidth **only controls the global\nentropy** of the affinity.\n\nIn ``TorchDR``, we can easily implement it using\n:class:`torchdr.affinity.GibbsAffinity` and setting the\nparameter ``normalization_dim=1``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "K = GibbsAffinity(\n    sigma=1, normalization_dim=1, keops=False, nodiag=False\n).fit_transform(X)\n\nplt.figure(1, (6, 3))\n\nplt.subplot(1, 2, 1)\nplt.imshow(K, cmap=cm.Blues)\nplt.title(\"Gibbs Affinity Matrix\")\n\nplt.subplot(1, 2, 2)\nplot_affinity_graph(K)\nplt.scatter(X[:, 0], X[:, 1], alpha=0.5)\nplt.title(\"Gibbs Affinity Graph\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can observe a remarkable **heterogeneity in the density of connections**.\nThis occurs because it is less costly to create connections in high-density regions.\nAs a consequence, points in sparse regions create very few connections with\ntheir neighbors.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entropic affinity (adaptive bandwidth)\n\nTo remedy this issue, we can use an **entropic affinity**. The entropic affinity\nemploys an **adaptive bandwidth** that depends on the local density of points.\nBy controling the entropy of each row of the affinity matrix, it ensures that\n**each point has the same number of effective neighbors** (given by\nthe ``perplexity`` parameter) regardless of the local density around it.\n\nIn ``TorchDR``, this object is available here :\n:class:`torchdr.affinity.EntropicAffinity` .\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "EA = EntropicAffinity(\n    perplexity=5, keops=False, verbose=False, nodiag=False\n).fit_transform(X)\n\nplt.figure(1, (6, 3))\n\nplt.subplot(1, 2, 1)\nplt.imshow(EA, cmap=cm.Blues)\nplt.title(\"Entropic Affinity Matrix\")\n\nplt.subplot(1, 2, 2)\nplot_affinity_graph(EA)\nplt.scatter(X[:, 0], X[:, 1], alpha=0.5)\nplt.title(\"Entropic Affinity Graph\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now observe a **homogeneous density of connections** across clusters.\nThus, the entropic affinity effectively filters out the various noise levels.\n\nThis affinity is an important component of the **TSNE** algorithm,\navailable in ``TorchDR`` at :class:`torchdr.neighbor_embedding.TSNE`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}